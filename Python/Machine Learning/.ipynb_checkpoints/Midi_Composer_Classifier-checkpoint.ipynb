{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76efb728",
   "metadata": {},
   "source": [
    "# Midi Composer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5786b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'MusicNet\\\\PS1'\n",
    "prediction_path = 'MusicNet\\\\PS2'\n",
    "stream_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cd777",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "66377241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import pretty_midi\n",
    "\n",
    "import warnings \n",
    "from os import listdir\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c79515",
   "metadata": {},
   "source": [
    "### Collect Known Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e36158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    \"\"\"\n",
    "    This function flattens a list of list of lists into a list of lists\n",
    "    \n",
    "    @input features: list of list of lists\n",
    "    @type features: list of list of lists\n",
    "    \n",
    "    @return: list of lists\n",
    "    @rtype: list of lists\n",
    "    \"\"\"\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c6c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    This function normalizes the features to the range [-1, 1]\n",
    "    \n",
    "    @input features: The array of features.\n",
    "    @type features: List of float\n",
    "    \n",
    "    @return: Normalized features.\n",
    "    @rtype: List of float\n",
    "    \"\"\"\n",
    "    tempo = (features[0] - 150) / 300\n",
    "    resolution = (features[1] - 260) / 400\n",
    "    num_tempo_changes = (features[2] - 2) / 10\n",
    "    num_sig_changes = (features[3] - 2) / 10\n",
    "    num_instruments = (features[4] - 5) / 40\n",
    "    \n",
    "    return [tempo, resolution, num_tempo_changes,\n",
    "            num_sig_changes, num_instruments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "438df02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tempo(tempo_changes, chunk_min, chunk_max):\n",
    "    \"\"\"\n",
    "    Retreives tempo at start of chunk and,\n",
    "    number of tempo changes for a given chunk\n",
    "    \n",
    "    @input tempo_changes: total list of tempo changes\n",
    "    @type instruments: pretty_midi.Instrument\n",
    "    @input chunk_min: time of starting chunk\n",
    "    @type chunk_min: int\n",
    "    @input chunk_max: time of ending chunk\n",
    "    @type chunk_max: int\n",
    "    \n",
    "    @return: starting tempo and number of tempo changes in for chunk\n",
    "    @rtype: [float, Int]\n",
    "    \"\"\"\n",
    "    tempo = tempo_changes[0][1]\n",
    "    num_tempo_changes = 0\n",
    "    \n",
    "    for i_tempo in tempo_changes:\n",
    "        if chunk_min <= i_tempo[0] <= chunk_max:\n",
    "            tempo = i_tempo[1]\n",
    "            num_tempo_changes += 1\n",
    "    \n",
    "    return [tempo, num_tempo_changes]\n",
    "\n",
    "def get_num_sig_changes(time_sig_changes, chunk_min, chunk_max):\n",
    "    \"\"\"\n",
    "    Retreives number of time signature changes for a given chunk\n",
    "    \n",
    "    @input time_sig_changes: total list of time signature changes\n",
    "    @type instruments: pretty_midi.Instrument\n",
    "    @input chunk_min: time of starting chunk\n",
    "    @type chunk_min: int\n",
    "    @input chunk_max: time of ending chunk\n",
    "    @type chunk_max: int\n",
    "    \n",
    "    @return: number of time signature changes\n",
    "    @rtype: Int\n",
    "    \"\"\"\n",
    "    num_sig_changes = 0\n",
    "    \n",
    "    for i_time_sig in time_sig_changes:\n",
    "        if chunk_min <= i_time_sig.time <= chunk_max:\n",
    "            num_sig_changes += 1\n",
    "    \n",
    "    return num_sig_changes\n",
    "\n",
    "def get_num_instruments(instruments, chunk_min, chunk_max, fs_min, fs_max):\n",
    "    \"\"\"\n",
    "    Retreives number of instruments for a given chunk\n",
    "    \n",
    "    @input instruments: total list of instruments\n",
    "    @type instruments: pretty_midi.Instrument\n",
    "    @input chunk_min: time of starting chunk\n",
    "    @type chunk_min: int\n",
    "    @input chunk_max: time of ending chunk\n",
    "    @type chunk_max: int\n",
    "    @input fs_min: relates to start time of chunk\n",
    "    @type fs_min: int\n",
    "    @input fs_max: relates to end time of chunk\n",
    "    @type fs_max: int\n",
    "    \n",
    "    @return: number of instruments\n",
    "    @rtype: Int\n",
    "    \"\"\"\n",
    "    num_instruments = 0\n",
    "    \n",
    "    for i_instrument in instruments:\n",
    "        instrument_value = sum(sum(i_instrument.get_piano_roll())[fs_min:fs_max])\n",
    "        if instrument_value != 0:\n",
    "            num_instruments += 1\n",
    "    \n",
    "    return num_instruments\n",
    "\n",
    "def get_fs_frac(file, num_chunks):\n",
    "    \"\"\"\n",
    "    gets the size of fs_frac, which is dependent on chunk_size\n",
    "    \n",
    "    @input file: midi file path\n",
    "    @type file: String\n",
    "    @input num_chunks: number of chunks in this file's length\n",
    "    @type num_chunks: int\n",
    "    \n",
    "    @return: fraction of fs\n",
    "    @rtype: Int\n",
    "    \"\"\"\n",
    "    piano_roll = file.get_piano_roll()\n",
    "    fs = piano_roll.shape[1]\n",
    "    return (fs/num_chunks).astype('int')\n",
    "\n",
    "def split_midi_features(file, chunk_size):\n",
    "    \"\"\"\n",
    "    Splits midi files into a number of sizes depending on chunk size.\n",
    "    Retrieves features for each midi file chunk\n",
    "    \n",
    "    @input file: midi file path\n",
    "    @type file: String\n",
    "    @input chunk_size: length of streaming chunk\n",
    "    @type chunk_size: int\n",
    "    \n",
    "    @return: Extracted features\n",
    "    @rtype: List of lists of floats\n",
    "    \"\"\"\n",
    "    song_length = file.get_end_time()\n",
    "    num_chunks = np.floor(song_length/chunk_size).astype('int')\n",
    "    if num_of_chunks < 1:\n",
    "        num_of_chunks = 1\n",
    "    \n",
    "    tempo_changes = file.get_tempo_changes()\n",
    "    resolution = file.resolution\n",
    "    time_sig_changes = file.time_signature_changes\n",
    "    instruments = file.instruments\n",
    "    \n",
    "    fs_frac = get_fs_frac(file, num_chunks)\n",
    "    \n",
    "    list_of_chunk_features = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        chunk_min = chunk_size*(i)\n",
    "        chunk_max = chunk_size*(i+1)\n",
    "        \n",
    "        fs_min = fs_frac*(i)\n",
    "        fs_max = fs_frac*(i+1)\n",
    "        \n",
    "        tempo, num_tempo_changes = get_tempo(tempo_changes, chunk_min, chunk_max)\n",
    "        num_sig_changes = get_num_sig_changes(time_sig_changes, chunk_min, chunk_max)\n",
    "        num_instruments = get_num_instruments(instruments, chunk_min, chunk_max, fs_min, fs_max)\n",
    "        \n",
    "        norm_features = normalize_features([tempo, resolution, num_tempo_changes, \n",
    "                        num_sig_changes, num_instruments])\n",
    "        \n",
    "        list_of_chunk_features.append(norm_features)\n",
    "    \n",
    "\n",
    "    return list_of_chunk_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f79658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_features(file, chunk_size):\n",
    "    \"\"\"\n",
    "    Retrieves features for midi files\n",
    "    \n",
    "    @input file: midi file path\n",
    "    @type file: String\n",
    "    \n",
    "    @return: Extracted features\n",
    "    @rtype: List of floats\n",
    "    \"\"\"\n",
    "    resolution = file.resolution\n",
    "    \n",
    "    song_length = file.get_end_time()\n",
    "    num_chunks = np.floor(song_length/chunk_size).astype('int')\n",
    "    fs_frac = get_fs_frac(file, num_chunks)\n",
    "    \n",
    "    tempo, num_tempo_changes = get_tempo(file.get_tempo_changes(), 0, chunk_size)\n",
    "    num_sig_changes = get_num_sig_changes(file.time_signature_changes, 0, chunk_size)\n",
    "    num_instruments = get_num_instruments(file.instruments, 0, chunk_size, 0, fs_frac)\n",
    "    \n",
    "    return normalize_features([tempo, resolution, num_tempo_changes, \n",
    "                        num_sig_changes, num_instruments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22c9ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(song, chunk_size=30, split_midi=False):\n",
    "    \"\"\"\n",
    "    This function checks for a corrupt midi file, \n",
    "    it extracts certain features, and creates a list of lists.\n",
    "    \n",
    "    @input song: midi file path\n",
    "    @type song: String\n",
    "    \n",
    "    @return: Extracted features\n",
    "    @rtype: List of lists\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Test for Corrupted Midi Files\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "            file = pretty_midi.PrettyMIDI(song)\n",
    "            \n",
    "            if split_midi:\n",
    "                return split_midi_features(file, chunk_size)\n",
    "            \n",
    "            return midi_features(file, chunk_size)\n",
    "                \n",
    "    \n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd2a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bach\n",
      "Beethoven\n",
      "Brahms\n",
      "Schubert\n",
      "2273 midi segments\n"
     ]
    }
   ],
   "source": [
    "def composers_list(path, composer, chunk_size):\n",
    "    \"\"\"\n",
    "    This function takes a folder location and a composer folder name, \n",
    "    and returns a list of songs with features.\n",
    "    \n",
    "    @input path: folder of composer folders\n",
    "    @type path: String\n",
    "    @input composer: folder of composer's songs\n",
    "    @type composer: String\n",
    "    \n",
    "    @return: Songs (w/ features) of composer\n",
    "    @rtype: List of lists\n",
    "    \"\"\"\n",
    "    print(composer)\n",
    "    all_features = []\n",
    "    composer_path = join(path, composer)\n",
    "\n",
    "    for song in listdir(composer_path):\n",
    "        song_path = join(composer_path, song) \n",
    "        chunk_features = get_features(song_path, chunk_size, split_midi=True)\n",
    "        \n",
    "        if chunk_features is not None:\n",
    "            for features in chunk_features:\n",
    "                features.append(composer)\n",
    "                all_features.append(features)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# Creates midi list with features for each composer \n",
    "composers = listdir(training_path)\n",
    "composers_features = [composers_list(training_path, composer, stream_size) for composer in composers]\n",
    "\n",
    "labeled_features = flatten(composers_features)\n",
    "print(f'{len(labeled_features)} midi segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0335a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24571441000000002, 0.55, -0.1, -0.1, -0.1, 'Bach']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776302a",
   "metadata": {},
   "source": [
    "### Partition Dataset and Format Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d9a95d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.49347826  0.31       -0.2        -0.2        -0.075     ]\n",
      " [-0.475       0.31       -0.1        -0.1        -0.075     ]\n",
      " [-0.424       0.31       -0.1        -0.1        -0.075     ]\n",
      " [-0.4475      0.31       -0.2        -0.2        -0.075     ]\n",
      " [-0.31333323  0.31       -0.1        -0.2        -0.025     ]]\n",
      "[1 1 1 1 1]\n",
      "[[0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "composer_label = {'Bach' : 0, 'Beethoven' : 1, 'Brahms' : 2, 'Schubert' : 3}\n",
    "\n",
    "def partition_dataset(labeled_features):\n",
    "    \"\"\"\n",
    "    Separates labeled_features into 3 groups:\n",
    "    60% for training, 20% for validation, and 20% for testing accuracy\n",
    "    \n",
    "    @input labeled_features: The total list of labeled features\n",
    "    @type labeled_features: list of mostly floats and one String column\n",
    "    \n",
    "    @return: the three separate groups of data\n",
    "    @rtype: list of lists\n",
    "    \"\"\"\n",
    "    num = len(labeled_features)\n",
    "    num_training = int(num * 0.6)\n",
    "    num_validation = int(num * 0.8)\n",
    "    training_data = labeled_features[:num_training]\n",
    "    validation_data = labeled_features[num_training:num_validation]\n",
    "    test_data = labeled_features[num_validation:]\n",
    "    \n",
    "    return [training_data, validation_data, test_data]\n",
    "\n",
    "def get_data_features(data, num_cols):\n",
    "    \"\"\"\n",
    "    Makes a feature list from data\n",
    "    \n",
    "    @input data: The total label_feature data\n",
    "    @type data: list of mostly floats and one String column\n",
    "    @input num_cols: The number of columns in each labeled_feature\n",
    "    @type num_cols: int\n",
    "    \n",
    "    @return: array of all features of that category of data\n",
    "    @rtype: numpy array of floats\n",
    "    \"\"\"\n",
    "    return np.array(data[:, :num_cols]).astype('float')\n",
    "\n",
    "def get_data_labels(data, num_cols):\n",
    "    \"\"\"\n",
    "    Makes a label list from data. Then converts composer's name to an int value\n",
    "    \n",
    "    @input data: The total label_feature data\n",
    "    @type data: list of mostly floats and one String column\n",
    "    @input num_cols: The number of columns in each labeled_feature\n",
    "    @type num_cols: int\n",
    "    \n",
    "    @return: array of all labels of that category of data\n",
    "    @rtype: numpy array of ints\n",
    "    \"\"\"\n",
    "    labels_list = [composer_label[person] for person in data[:, num_cols]]\n",
    "    return np.array(labels_list).astype('int')\n",
    "\n",
    "def partition_dataset_and_format_features(labeled_features):\n",
    "    \"\"\"\n",
    "    This function first randomizes the order of labeled_features,\n",
    "    then separates features and labels from each other.\n",
    "    \n",
    "    @input labeled_features: The total list of labeled features\n",
    "    @type labeled_features: list of mostly floats and one String column\n",
    "    \n",
    "    @return: Two dictionaries, one for features and one for labels\n",
    "    @rtype: list of 2 dictionaries\n",
    "    \"\"\"\n",
    "    # Shuffle Entire Dataset to Make Random\n",
    "    labeled_features = np.random.permutation(labeled_features)\n",
    "    \n",
    "    # Partition into 3 sets\n",
    "    training_data, validation_data, test_data = partition_dataset(labeled_features)\n",
    "    \n",
    "    # Separate Features from Labels\n",
    "    num_cols = training_data.shape[1] - 1\n",
    "    training_features = get_data_features(training_data, num_cols)\n",
    "    validation_features = get_data_features(validation_data, num_cols)\n",
    "    test_features = get_data_features(test_data, num_cols)\n",
    "    \n",
    "    features = {\n",
    "        'train' : training_features,\n",
    "        'validate' : validation_features,\n",
    "        'test' : test_features\n",
    "    }\n",
    "    \n",
    "    # Format Features for Multi-class Classification\n",
    "    training_labels = get_data_labels(training_data, num_cols)\n",
    "    validation_labels = get_data_labels(validation_data, num_cols)\n",
    "    test_labels = get_data_labels(test_data, num_cols)\n",
    "    \n",
    "    labels = {\n",
    "        'train' : training_labels,\n",
    "        'validate' : validation_labels,\n",
    "        'test' : test_labels\n",
    "    }\n",
    "\n",
    "    return [features, labels]\n",
    "\n",
    "# Function for One-Hot Encoding\n",
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    This function encodes the labels using one-hot encoding.\n",
    "    \n",
    "    @input num_classes: The number of genres/classes.\n",
    "    @type num_classes: int\n",
    "    @input labels: The genre labels to encode.\n",
    "    @type labels: list of int\n",
    "    \n",
    "    @return: The one-hot encoding of the labels.\n",
    "    @rtype: numpy.ndarray of int\n",
    "    \"\"\"\n",
    "    return np.eye(len(composers))[labels].astype(int)\n",
    "\n",
    "# Print to Check Dimentions and to Visualize\n",
    "features, labels = partition_dataset_and_format_features(labeled_features)\n",
    "\n",
    "print(features['test'][:5])\n",
    "print(labels['test'][:5])\n",
    "print(one_hot(labels['test'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee7a9d",
   "metadata": {},
   "source": [
    "### Construct Models to Fit Labeled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "308d8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(t_features, t_labels, v_features, v_labels):\n",
    "    \"\"\"\n",
    "    This function trains a neural network using a couple different configurations.\n",
    "    \n",
    "    @input t_features: The training features.\n",
    "    @type t_features: numpy.ndarray of float\n",
    "    @input t_labels: The training labels.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    @input v_features: The validation features.\n",
    "    @type v_features: numpy.ndarray of float\n",
    "    @input v_labels: The validation labels.\n",
    "    @type v_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The classifier that achieved the best validation accuracy.\n",
    "    @rtype: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    \"\"\"\n",
    "    # Neural Network and SVM Configurations\n",
    "    clf_list = []\n",
    "    #clf_list.append(MLPClassifier(hidden_layer_sizes=(5), random_state=1, max_iter=1000))\n",
    "    #clf_list.append(MLPClassifier(hidden_layer_sizes=(5, 5), random_state=1, max_iter=5000))\n",
    "    #clf_list.append(MLPClassifier(hidden_layer_sizes=(10, 10), random_state=1, max_iter=5000))\n",
    "    #clf_list.append(MLPClassifier(hidden_layer_sizes=(100, 100), random_state=1, max_iter=1000))\n",
    "    #clf_list.append(SVC())\n",
    "    clf_list.append(KNeighborsClassifier(n_neighbors=5))\n",
    "    \n",
    "    # Keep Track of the Best Model\n",
    "    best_clf = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Test the Accuracies of the Models and Get Best\n",
    "    for clf in clf_list:\n",
    "        t_labels_hot = one_hot(t_labels)\n",
    "        v_labels_hot = one_hot(v_labels)\n",
    "        \n",
    "        if (type(clf) == SVC):\n",
    "            clf = clf.fit(t_features, t_labels)\n",
    "        else:\n",
    "            clf = clf.fit(t_features, t_labels_hot)\n",
    "            \n",
    "        predictions = clf.predict(v_features)\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(len(v_labels)):\n",
    "            if (type(clf) != SVC):\n",
    "                if np.array_equal(v_labels_hot[i], predictions[i]):\n",
    "                    count += 1\n",
    "            else:\n",
    "                if v_labels[i] == predictions[i]:\n",
    "                    count += 1\n",
    "                    \n",
    "        accuracy = count / len(v_labels_hot)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_clf = clf\n",
    "\n",
    "    #print(\"Best Accuracy:\", best_accuracy)\n",
    "    #print(\"Best Classifier:\", best_clf)\n",
    "    \n",
    "    return best_clf\n",
    "\n",
    "# Find classifier with the best accuracy\n",
    "classifier = train_model(features['train'], labels['train'], features['validate'], labels['validate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf07cf",
   "metadata": {},
   "source": [
    "### Calculate Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5a729d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9494505494505494\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(clf, t_features, t_labels):\n",
    "    \"\"\"\n",
    "    This function takes a trained model as well as the test features and its\n",
    "    corresponding labels, and reports the accuracy of the model.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type model: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input t_features: The features from the test set.\n",
    "    @type f_features: numpy.ndarray of float\n",
    "    @input t_labels: The labels of the test set features.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The accuracy.\n",
    "    @rtype: float\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    predictions = clf.predict(t_features)\n",
    "    t_labels_hot = one_hot(t_labels)\n",
    "    for i in range(len(t_features)):\n",
    "        if (type(clf) == SVC):\n",
    "            if t_labels[i] == predictions[i]:\n",
    "                count += 1\n",
    "        else:\n",
    "            if np.array_equal(t_labels_hot[i], predictions[i]):\n",
    "                count += 1\n",
    "    return count / len(t_features)\n",
    "\n",
    "# Print the Test Accuracy\n",
    "print(calculate_accuracy(classifier, features['test'], labels['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee38d2",
   "metadata": {},
   "source": [
    "### Predict PS2 midi composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7f232340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midi</th>\n",
       "      <th>composer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10222964826466285_adj.mid</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.647959423719129_adj.mid</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           midi composer\n",
       "6   0.10222964826466285_adj.mid    Other\n",
       "28    0.647959423719129_adj.mid    Other"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_prediction(clf, midi_path):\n",
    "    \"\"\"\n",
    "    This function uses the classifier to predict the genre of a midi file.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type clf: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input midi_path: The path to the midi file that we are trying to classify.\n",
    "    @type midi_path: String\n",
    "    \n",
    "    @return: The predicted genre of the midi file.\n",
    "    @rtype: String\n",
    "    \"\"\"\n",
    "    features = get_features(midi_path, chunk_size=stream_size, split_midi=False)\n",
    "    \n",
    "    if features is None:\n",
    "        return 'None'\n",
    "    \n",
    "    if (type(clf) != SVC):\n",
    "        prediction = list(clf.predict([features])[0])\n",
    "        \n",
    "        if prediction == [0,0,0,0]:\n",
    "            return 'Other'\n",
    "        \n",
    "        prediction_ind = prediction.index(1)\n",
    "    \n",
    "    else:\n",
    "        prediction_ind = clf.predict([features])[0]\n",
    "    \n",
    "    return [k for k, v in composer_label.items() if v == prediction_ind][0]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# Make a Prediction\n",
    "midi_list = [midi for midi in listdir(prediction_path)]\n",
    "\n",
    "df = pd.DataFrame({'midi':midi_list})\n",
    "\n",
    "df['composer'] = df.apply (lambda row: make_prediction(classifier, join(prediction_path, row.midi)), axis=1)\n",
    "\n",
    "other_composers = df.loc[(df['composer'] == 'Other')]\n",
    "other_composers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3a16a",
   "metadata": {},
   "source": [
    "## Making histogram of it's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "320aeda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({15: 2, 26: 16, 30: 3, 10: 8, 20: 22, 23: 17, 6: 3, 28: 3})"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vals = []\n",
    "\n",
    "midi_list = [midi for midi in listdir(prediction_path)]\n",
    "\n",
    "for i in range(50):\n",
    "    # Print to Check Dimentions and to Visualize\n",
    "    features, labels = partition_dataset_and_format_features(labeled_features)\n",
    "\n",
    "    # Find classifier with the best accuracy\n",
    "    classifier = train_model(features['train'], labels['train'], features['validate'], labels['validate'])\n",
    "    \n",
    "    # Make a Prediction\n",
    "    df = pd.DataFrame({'midi':midi_list})\n",
    "    df['composer'] = df.apply (lambda row: make_prediction(classifier, join(prediction_path, row.midi)), axis=1)\n",
    "\n",
    "    other_composers = df.loc[(df['composer'] == 'Other')]\n",
    "    count_vals.append(other_composers.index.values.tolist())\n",
    "    \n",
    "Counter(flatten(count_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a6a6624f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unknown_author_freq = Counter(flatten(count_vals)).most_common()\n",
    "                    \n",
    "x_vals = [str(val[0]) for val in unknown_author_freq]\n",
    "y_vals = [val[1] for val in unknown_author_freq]\n",
    "\n",
    "plt.bar(x_vals, y_vals)\n",
    "plt.xticks(x_vals)\n",
    "plt.ylabel('Frequency of not being selected')\n",
    "plt.xlabel('df index number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2859ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three most-likey compositions to not be written by the 4 known composers are\n",
      "['0.337517805339117_adj.mid', '0.36321860283443286_adj.mid', '0.549470161204349_adj.mid']\n"
     ]
    }
   ],
   "source": [
    "three_most_likely_ind = Counter(flatten(count_vals)).most_common(3)\n",
    "\n",
    "three_most_likely_midi = [df.iloc[val[0]]['midi'] for val in three_most_likely_ind]\n",
    "print(f'The three most-likey compositions to not be written by the 4 known composers are')\n",
    "print(three_most_likely_midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ea9c9",
   "metadata": {},
   "source": [
    "## Discussion and Improvements\n",
    "Since two pieces of musics written by two different people can sound very similar, I'm not really sure I would say we are noise limited. Also, any of these 4 composers are so famous and wrote so many pieces, that they have pieces that do not sound like their other pieces, and do sound like pieces written by other people.\n",
    "\n",
    "I do not think data limited applies here, or a 'limit imposed on the amount of data that can be transferred to an electronic device'. I think the midi files were fairly complete.\n",
    "\n",
    "The discussion on underfitting vs overfitting is interesting. Before I tried the KNN model, I would've argued that the data was underfitted due to lack of data. However, after using KNN, and taking many iterations of the results to find a distribution of the 'midi files with unknown composers', I do think it's close to optimal. Obviously, it's not 100% accurate, but I think that would be:\n",
    "   1. 100% accuracy would probably need lots of data with no noise, which isn't realistic\n",
    "   2. if 100% was ever achieved, it would probably be overfitted for these four composers\n",
    "   3. some of these composers are going to have songs that sound like one anothers, so it's should be wrong occasionally \n",
    "\n",
    "Lastly, I would probably improve the model by figuring out how to collect more useful features from the midi files. This was my first time looking at midi file data. Also, collecting more data of the same composers or data with other composers that can be labeled as 'other' would improve the model. There's also an argument for doing a more robust hyperparameter study on the KNN (and other) model(s) to find the most optimal solution. There's probably a need to test for more missing data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abeb06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
